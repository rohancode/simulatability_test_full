{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import keras\n",
    "# keras version: 2.2.4\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gtrain import FCNet\n",
    "\n",
    "import tensorflow as tf\n",
    "# tensorflow version: 1.13.1\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import csv\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/Rohan/Desktop/Cl/XAI/simulatability_tests/simulatability_test_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ruleex_modified.ruleex.deepred.model import DeepRedFCNet\n",
    "import ruleex_modified.ruleex.anndt as ndt\n",
    "import ruleex_modified.ruleex.deepred as dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:54<00:00, 229.48it/s]\n",
      "100%|██████████| 12500/12500 [00:49<00:00, 252.84it/s]\n",
      "100%|██████████| 12500/12500 [00:49<00:00, 254.95it/s]\n",
      "100%|██████████| 12500/12500 [01:11<00:00, 175.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Data: https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "base_folder = '/Users/Rohan/Desktop/Rohan/XAI/aclImdb/'\n",
    "\n",
    "def parse_folder(name):\n",
    "    data = []\n",
    "    for verdict in ('neg', 'pos'):\n",
    "        for file in tqdm(glob(os.path.join(name, verdict, '*.txt'))):\n",
    "            data.append({\n",
    "                'text': open(file, encoding='utf8').read(),\n",
    "                'verdict': verdict\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_train = parse_folder(base_folder+'train/')\n",
    "df_test = parse_folder(base_folder+'test/')\n",
    "\n",
    "df = pd.concat([df_train, df_test])\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(['index'], axis=1, inplace=True)\n",
    "df = df.sample(frac=1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    10123\n",
       "neg     9877\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.verdict.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29430</th>\n",
       "      <td>This movie's script is indistinguishable from ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27750</th>\n",
       "      <td>I've been surprised by the enthusiastic respon...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47782</th>\n",
       "      <td>I don't know why critics cal it bizarre and ma...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>\"The Domino Principle\" is, without question, o...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24747</th>\n",
       "      <td>This movie has its ups and downs, but to me th...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text verdict\n",
       "29430  This movie's script is indistinguishable from ...     neg\n",
       "27750  I've been surprised by the enthusiastic respon...     neg\n",
       "47782  I don't know why critics cal it bizarre and ma...     pos\n",
       "10498  \"The Domino Principle\" is, without question, o...     neg\n",
       "24747  This movie has its ups and downs, but to me th...     pos"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df['text'])\n",
    "sentiment = list(df['verdict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, sentiment_train, sentiment_test = train_test_split(sentences, sentiment, test_size=0.20, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(list(map(lambda x: [0,1] if x=='pos' else [1,0], sentiment_train)))\n",
    "y_test = np.array(list(map(lambda x: [0,1] if x=='pos' else [1,0], sentiment_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    sentence = re.sub('[^A-Za-z0-9]', ' ', sen)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    sentence_clean = \"\"\n",
    "    \n",
    "    for w in word_tokenize(sentence):\n",
    "        if (w not in stop_words) & (len(w)>2):\n",
    "            sentence_clean = sentence_clean + \" \" + ps.stem(w)\n",
    "    return sentence_clean.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16000/16000 [01:34<00:00, 168.81it/s]\n",
      "100%|██████████| 4000/4000 [00:23<00:00, 172.69it/s]\n"
     ]
    }
   ],
   "source": [
    "X_preprocess_train = []\n",
    "for sen in tqdm(sentences_train):\n",
    "    X_preprocess_train.append(preprocess_text(sen))\n",
    "    \n",
    "X_preprocess_test = []\n",
    "for sen in tqdm(sentences_test):\n",
    "    X_preprocess_test.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X_vectorized_train = vectorizer.fit_transform(X_preprocess_train)\n",
    "X_vectorized_test = vectorizer.transform(X_preprocess_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectorized_test_array = pd.DataFrame(X_vectorized_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectorized_test_array.to_csv('test_vectors_210303.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = list(vectorizer.vocabulary_.values())\n",
    "w = list(vectorizer.vocabulary_.keys())\n",
    "voc = {}\n",
    "for i, j in enumerate(v):\n",
    "    voc[j] = w[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary_210303.csv', 'w') as f:\n",
    "    for key in voc.keys():\n",
    "        f.write(\"%s,%s\\n\"%(key,voc[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words = list(vectorizer.vocabulary_.keys())\n",
    "vocab_idx = list(vectorizer.vocabulary_.values())\n",
    "vocab_inv = {}\n",
    "for i, idx in enumerate(vocab_idx):\n",
    "    vocab_inv[idx] = vocab_words[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Rohan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "  Dense(100, activation='relu', input_shape=(500,)),\n",
    "  Dense(30, activation='relu'),\n",
    "  Dense(2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Rohan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "16000/16000 [==============================] - 2s 107us/step - loss: 0.4107 - acc: 0.8130\n",
      "Epoch 2/3\n",
      "16000/16000 [==============================] - 1s 92us/step - loss: 0.3415 - acc: 0.8468\n",
      "Epoch 3/3\n",
      "16000/16000 [==============================] - 1s 91us/step - loss: 0.3229 - acc: 0.8560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c8187d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_vectorized_train, y_train , epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 1s 39us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2853238100260496, 0.8778125]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_vectorized_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.365697248339653, 0.8385]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_vectorized_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ANN-DT</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'dir_imdb_anndt'\n",
    "data = 'imdb'\n",
    "method = 'anndt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = data + \"_\" + method\n",
    "tat_params = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tat_params[\"save_dir\"] = os.path.join(\"runs\", directory, name)\n",
    "if not os.path.isdir(tat_params[\"save_dir\"]):\n",
    "    os.makedirs(tat_params[\"save_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tat_params[\"init_restrictions\"] = np.array([[0, 1] for _ in range(500)])\n",
    "tat_params[\"act_val_num\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TaT_anndt(tr_in_dict, tr_out_dict, tst_in_dict, tst_out_dict, params):\n",
    "    \n",
    "    layer_sizes = []\n",
    "    layer_sizes.append(500)\n",
    "    for layer in model.layers:\n",
    "        layer_sizes.append(layer.output_shape[-1])\n",
    "    \n",
    "    weights = model.get_weights()\n",
    "    \n",
    "    net = DeepRedFCNet(layer_sizes)\n",
    "    net.init_eval_weights(weights)\n",
    "    \n",
    "    p = {\n",
    "        \"varbose\": 1,\n",
    "        ndt.ATTRIBUTE_SELECTION: False,\n",
    "    }\n",
    "\n",
    "    if \"min_train_samples\" in params:\n",
    "        p[ndt.MIN_TRAIN_SAMPLES] = params[\"min_train_samples\"]\n",
    "\n",
    "    if \"max_depth\" not in params:\n",
    "        p[ndt.MAX_DEPTH] = 10\n",
    "    else:\n",
    "        p[ndt.MAX_DEPTH] = params[\"max_depth\"]\n",
    "\n",
    "    if \"min_samples\" in params:\n",
    "        p[ndt.MIN_SAMPLES] = params[\"min_samples\"]\n",
    "\n",
    "    if \"min_split_fraction\" in params:\n",
    "        p[ndt.MIN_SPLIT_FRACTION] = params[\"min_split_fraction\"]\n",
    "\n",
    "    stat_test = None\n",
    "    if \"split_test\" in params:\n",
    "        if params[\"split_test\"]==\"t\":\n",
    "            stat_test = ndt.test_t\n",
    "        elif params[\"split_test\"] == \"welch\":\n",
    "            stat_test = ndt.test_welch\n",
    "        elif params[\"split_test\"] == \"chi2\":\n",
    "            stat_test = ndt.test_chi2\n",
    "        elif params[\"split_test\"] == \"f\":\n",
    "            stat_test = ndt.test_F\n",
    "        else:\n",
    "            stat_test = ndt.test_chi2\n",
    "    else:\n",
    "        stat_test = ndt.test_chi2\n",
    "\n",
    "    if \"measure\" in params:\n",
    "        if params[\"measure\"]==\"gini\":\n",
    "            measure = ndt.GiniMeasure\n",
    "        elif params[\"measure\"]==\"missclass\":\n",
    "            measure = ndt.FidelityGain\n",
    "        elif params[\"measure\"]==\"maxdiff\":\n",
    "            measure = ndt.MaxDifference\n",
    "        elif params[\"measure\"]==\"var\":\n",
    "            measure = ndt.VarianceMeasure\n",
    "        else:\n",
    "            measure = ndt.EntropyMeasure\n",
    "    else:\n",
    "        measure = ndt.EntropyMeasure\n",
    "\n",
    "    if \"attr_selection\" in params:\n",
    "        if params[\"attr_selection\"]==\"absvar\":\n",
    "            p[ndt.ATTRIBUTE_SELECTION] = ndt.MODE_ABSOLUTE_VARIATION\n",
    "        elif params[\"attr_selection\"]==\"missclass\":\n",
    "            p[ndt.ATTRIBUTE_SELECTION] = ndt.MODE_MISSCLASSIFICATION\n",
    "        elif params[\"attr_selection\"]==\"conmissclass\":\n",
    "            p[ndt.ATTRIBUTE_SELECTION] = ndt.MODE_CONTINUOUS_MISSCLASSIFICATION\n",
    "\n",
    "    if \"measure_weights\" in params:\n",
    "        if params[\"measure_weights\"]==\"train\":\n",
    "            p[ndt.MEASURE_WEIGHTS] = ndt.MODE_TRAIN\n",
    "        elif params[\"measure_weights\"]==\"all\":\n",
    "            p[ndt.MEASURE_WEIGHTS] = ndt.MODE_ALL\n",
    "        else:\n",
    "            p[ndt.MEASURE_WEIGHTS] = ndt.MODE_NONE\n",
    "\n",
    "    if \"force_sampling\" in params:\n",
    "        p[ndt.FORCE_SAMPLING] = params[\"force_sampling\"]\n",
    "\n",
    "    if \"num_samples\" in params:\n",
    "        indexes = np.random.permutation(len(tr_in_dict[\"x\"]))\n",
    "        x_train = tr_in_dict[\"x\"][indexes[:params[\"num_samples\"]]]\n",
    "    else:\n",
    "        x_train = tr_in_dict[\"x\"]\n",
    "\n",
    "    if \"vs_others\" in params:\n",
    "        model_anndt = lambda x: net.eval_binary_class(x, params[\"vs_others\"])\n",
    "    else:\n",
    "        model_anndt = net.eval\n",
    "\n",
    "    if \"init_restrictions\" in params:\n",
    "        res = params[\"init_restrictions\"]\n",
    "    else:\n",
    "        res = None\n",
    "\n",
    "    p[ndt.SPLIT_TEST_AFTER] = 3\n",
    "    rt = ndt.anndt(model_anndt, x_train, p,\n",
    "                   stat_test=stat_test,\n",
    "                   MeasureClass=measure,\n",
    "                   init_restrictions=res,\n",
    "                   sampler=ndt.BerNormalSampler(x_train, always_positive=True, sigma=0.01))\n",
    "    rt.save(os.path.join(params[\"save_dir\"], \"rt.pic\"))\n",
    "\n",
    "    dt = DecisionTreeClassifier(max_depth=p[\"max_depth\"])\n",
    "    dt.fit(x_train, np.argmax(model_anndt(x_train), axis=1))\n",
    "    dt = dr.sklearndt_to_ruletree(dt, one_class_on_leafs=True)\n",
    "    print(\"rt.view_graph()\")\n",
    "    rt.view_graph(filename='mnist_tree.pdf', varbose=True)\n",
    "    dt.save(os.path.join(params[\"save_dir\"], \"sklear_dt.pic\"))\n",
    "    inf = p[ndt.INF]\n",
    "    rt_train = rt.eval_all(tr_in_dict[\"x\"])\n",
    "    dt_train = dt.eval_all(tr_in_dict[\"x\"])\n",
    "    ln = np.argmax(model_anndt(tr_in_dict[\"x\"]), axis=1)\n",
    "    inf[\"fidelity\"] = np.mean(rt_train == ln)\n",
    "    inf[\"dt_fidelity\"] = np.mean(dt_train == ln)\n",
    "    rt_val = rt.eval_all(tst_in_dict[\"x\"])\n",
    "    dt_val = dt.eval_all(tst_in_dict[\"x\"])\n",
    "    l = np.argmax(tst_out_dict[\"y\"], axis=1)\n",
    "    ln = np.argmax(model_anndt(tst_in_dict[\"x\"]), axis=1)\n",
    "    inf[\"val_fidelity\"] = np.mean(ln == rt_val)\n",
    "    inf[\"val_accuracy\"] = np.mean(l == rt_val)\n",
    "    inf[\"dt_val_fidelity\"] = np.mean(ln == dt_val)\n",
    "    inf[\"dt_val_accuracy\"] = np.mean(l == dt_val)\n",
    "    print(\"Validation {}: fidelity {}, val_fidelity {}, val_accuracy {}\".format(params[\"act_val_num\"], inf[\"fidelity\"],\n",
    "                                                                                inf[\"val_fidelity\"],\n",
    "                                                                                inf[\"val_accuracy\"]))\n",
    "    print(\"Validation {}: fidelity {}, val_fidelity {}, val_accuracy {}\".format(params[\"act_val_num\"], inf[\"dt_fidelity\"],\n",
    "                                                                                inf[\"dt_val_fidelity\"],\n",
    "                                                                                inf[\"dt_val_accuracy\"]))\n",
    "    return inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_arr = X_vectorized_train.toarray()\n",
    "x_test_arr = X_vectorized_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 500)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[anndt]: Generated new node with split x_184 > 0.12212868540690353 in train samples separation (1319, 14681)\n",
      "[anndt]: Stopping rule - fraction of the founded node is to low so the leaf is generated.\n",
      "[anndt]: Generated new node with split x_137 > 0.14602508994997995 in train samples separation (439, 14242)\n",
      "[anndt]: Generated new node with split x_17 > 0.0906913246493002 in train samples separation (26, 413)\n",
      "[anndt]: Generating 24 new samples.\n",
      "[anndt]: Generated new node with split x_483 > 0.040682084971511 in train samples separation (6, 20)\n",
      "[anndt]: Generating 39 new samples.\n",
      "[anndt]: Generated new node with split x_2 > 0.10872737781205744 in train samples separation (0, 6)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 10 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 11 new samples.\n",
      "[anndt]: Generated new node with split x_17 > 0.2319114260446782 in train samples separation (5, 15)\n",
      "[anndt]: Generating 35 new samples.\n",
      "[anndt]: Generated new node with split x_137 > 0.21053630358289727 in train samples separation (5, 0)\n",
      "[anndt]: Generating 20 new samples.\n",
      "[anndt]: Generated new node with split x_42 > 0.2565940216141702 in train samples separation (0, 5)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 3 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 15 new samples.\n",
      "[anndt]: Generated new node with split x_304 > 0.02838384752354272 in train samples separation (7, 8)\n",
      "[anndt]: Generating 33 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 17 new samples.\n",
      "[anndt]: Generated new node with split x_44 > 0.05298989024289328 in train samples separation (2, 6)\n",
      "[anndt]: Generating 33 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 17 new samples.\n",
      "[anndt]: Generated new node with split x_128 > 0.08544428544999613 in train samples separation (2, 4)\n",
      "[anndt]: Generating 37 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 13 new samples.\n",
      "[anndt]: Generated new node with split x_14 > 0.11414546474857382 in train samples separation (0, 4)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 16 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generated new node with split x_137 > 0.2814492573163757 in train samples separation (69, 344)\n",
      "[anndt]: Generated new node with split x_122 > 0.13394351411201494 in train samples separation (4, 65)\n",
      "[anndt]: Generating 46 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generated new node with split x_201 > 0.14749353331147316 in train samples separation (3, 62)\n",
      "[anndt]: Generating 47 new samples.\n",
      "[anndt]: Generated new node with split x_224 > 0.3308300015538915 in train samples separation (0, 3)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 12 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generated new node with split x_7 > 0.04452710048239167 in train samples separation (4, 58)\n",
      "[anndt]: Generating 46 new samples.\n",
      "[anndt]: Generated new node with split x_19 > 0.07989816046371415 in train samples separation (1, 3)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 16 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generated new node with split x_313 > 0.16358634800500566 in train samples separation (2, 56)\n",
      "[anndt]: Generating 48 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Stopping rule - fraction of the founded node is to low so the leaf is generated.\n",
      "[anndt]: Generated new node with split x_313 > 0.12569981473105557 in train samples separation (17, 327)\n",
      "[anndt]: Generating 33 new samples.\n",
      "[anndt]: Generated new node with split x_425 > 0.05832768804401922 in train samples separation (13, 4)\n",
      "[anndt]: Generating 13 new samples.\n",
      "[anndt]: Generated new node with split x_18 > 0.0428946182187412 in train samples separation (1, 12)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 2 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 37 new samples.\n",
      "[anndt]: Generated new node with split x_219 > 0.16683841611981412 in train samples separation (1, 3)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 3 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generated new node with split x_432 > 0.11246397142683472 in train samples separation (19, 308)\n",
      "[anndt]: Generating 31 new samples.\n",
      "[anndt]: Generated new node with split x_77 > 0.07832865555803598 in train samples separation (1, 18)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 3 new samples.\n",
      "[anndt]: Generated new node with split x_106 > 0.13363168917781232 in train samples separation (2, 16)\n",
      "[anndt]: Generating 46 new samples.\n",
      "[anndt]: Generated new node with split x_137 > 0.17868746697802548 in train samples separation (1, 1)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 4 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generated new node with split x_499 > 0.10563427582000401 in train samples separation (20, 288)\n",
      "[anndt]: Generating 30 new samples.\n",
      "[anndt]: Generated new node with split x_437 > 0.09032434129712054 in train samples separation (2, 18)\n",
      "[anndt]: Generating 44 new samples.\n",
      "[anndt]: Generated new node with split x_65 > 0.146279040072264 in train samples separation (0, 2)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 4 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 6 new samples.\n",
      "[anndt]: Generated new node with split x_72 > 0.19545231092409437 in train samples separation (0, 18)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 2 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generated new node with split x_313 > 0.14478459361546564 in train samples separation (312, 13930)\n",
      "[anndt]: Generated new node with split x_313 > 0.29878738833458296 in train samples separation (39, 273)\n",
      "[anndt]: Generating 11 new samples.\n",
      "[anndt]: Generated new node with split x_54 > 0.06678804599946647 in train samples separation (4, 35)\n",
      "[anndt]: Generating 44 new samples.\n",
      "[anndt]: Generated new node with split x_286 > 0.11733495957828613 in train samples separation (0, 4)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 5 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 6 new samples.\n",
      "[anndt]: Generated new node with split x_257 > 0.16921376007561037 in train samples separation (5, 30)\n",
      "[anndt]: Generating 44 new samples.\n",
      "[anndt]: Generated new node with split x_257 > 0.19388961974322533 in train samples separation (5, 0)\n",
      "[anndt]: Generating 15 new samples.\n",
      "[anndt]: Generated new node with split x_184 > 0.0970099735010079 in train samples separation (0, 5)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 12 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 6 new samples.\n",
      "[anndt]: Generated new node with split x_147 > 0.10186643385627941 in train samples separation (2, 28)\n",
      "[anndt]: Generating 47 new samples.\n",
      "[anndt]: Generated new node with split x_92 > 0.14287853694189417 in train samples separation (0, 2)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 8 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 3 new samples.\n",
      "[anndt]: Generated new node with split x_41 > 0.1388626401747079 in train samples separation (1, 27)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 1 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generated new node with split x_195 > 0.1254788939019225 in train samples separation (12, 261)\n",
      "[anndt]: Generating 38 new samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[anndt]: Generated new node with split x_486 > 0.054789546605636424 in train samples separation (4, 8)\n",
      "[anndt]: Generating 34 new samples.\n",
      "[anndt]: Generated new node with split x_453 > 0.16025818468978456 in train samples separation (0, 4)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 9 new samples.\n",
      "[anndt]: Generated new node with split x_96 > 0.18708868103346504 in train samples separation (0, 4)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 1 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 16 new samples.\n",
      "[anndt]: Generated new node with split x_127 > 0.07200475957596184 in train samples separation (1, 7)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 7 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Stopping rule - fraction of the founded node is to low so the leaf is generated.\n",
      "[anndt]: Generated new node with split x_151 > 0.10649975228446559 in train samples separation (463, 13467)\n",
      "[anndt]: Generated new node with split x_67 > 0.03908697829367002 in train samples separation (19, 444)\n",
      "[anndt]: Generating 31 new samples.\n",
      "[anndt]: Generated new node with split x_349 > 0.13408094601939358 in train samples separation (3, 16)\n",
      "[anndt]: Generating 43 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 7 new samples.\n",
      "[anndt]: Generated new node with split x_223 > 0.03177697430701519 in train samples separation (2, 14)\n",
      "[anndt]: Generating 43 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Generating 7 new samples.\n",
      "[anndt]: Generated new node with split x_19 > 0.09933973512928555 in train samples separation (1, 13)\n",
      "[anndt]: stopping rule - low number of train samples\n",
      "[anndt]: Generating 1 new samples.\n",
      "[anndt]: Statistics test passed at confidence level 0.05\n",
      "[anndt]: Stopping rule - fraction of the founded node is to low so the leaf is generated.\n",
      "[anndt]: Stopping rule - fraction of the founded node is to low so the leaf is generated.\n",
      "rt.view_graph()\n",
      "Validation 0: fidelity 0.99, val_fidelity 0.98875, val_accuracy 0.4935\n",
      "Validation 0: fidelity 0.9875, val_fidelity 0.9885, val_accuracy 0.49275\n"
     ]
    }
   ],
   "source": [
    "inf = TaT_anndt({\"x\": x_train_arr}, {\"y\": y_train}, {\"x\": x_test_arr}, {\"y\": y_test}, tat_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make experimental data again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Case Selection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "random_cases = list(np.random.random_integers(0,3999,size=[500,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_data_idx = list(range(0,len(random_cases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_data_text = []\n",
    "for case_no_ in random_cases:\n",
    "    experimental_data_text.append(sentences_test[case_no_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_data_y = []\n",
    "for case_no_ in random_cases:\n",
    "    experimental_data_y.append(sentiment_test[case_no_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_data_y_hat = []\n",
    "for case_no_ in random_cases:\n",
    "    p = model.predict_classes(X_vectorized_test[case_no_])[0]\n",
    "    if p == 1:\n",
    "        experimental_data_y_hat.append('pos')\n",
    "    else:\n",
    "        experimental_data_y_hat.append('neg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CounterFactual example</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_purt_clas(case_no):\n",
    "    sentences_case = sentences_test[case_no]\n",
    "    sentences_case_word_tokens = word_tokenize(sentences_case)\n",
    "    sentences_case_length = len(sentences_case_word_tokens)\n",
    "    new_words_count = ceil(sentences_case_length/10)\n",
    "\n",
    "    random_words_index = list(np.random.random_integers(0,len(vocab_words)-1,size=[new_words_count,]))\n",
    "    new_words = []\n",
    "    for i in random_words_index:\n",
    "        new_words.append(vocab_words[i])\n",
    "\n",
    "    random_location_index = list(np.random.random_integers(0,sentences_case_length,size=[new_words_count,]))\n",
    "\n",
    "    sentences_new = \"\"\n",
    "    for i, w in enumerate(sentences_case_word_tokens):\n",
    "        if i in random_location_index:\n",
    "            sentences_new = sentences_new + \" **\" + new_words[np.where(np.array(random_location_index)==i)[0][0]] + \"**\"\n",
    "        else:\n",
    "            sentences_new = sentences_new + \" \" + w\n",
    "    sentences_new = sentences_new.strip()\n",
    "\n",
    "    text_list = [sentences_new]\n",
    "    X_preprocess = []\n",
    "    for sen in tqdm(text_list):\n",
    "        X_preprocess.append(preprocess_text(sen))\n",
    "\n",
    "    X_vectorized = vectorizer.transform(X_preprocess)\n",
    "\n",
    "    p = model.predict_classes(X_vectorized)[0]\n",
    "    \n",
    "    if p == 1:\n",
    "        clas = 'pos'\n",
    "    else:\n",
    "        clas = 'neg'\n",
    "    \n",
    "    return [sentences_new, clas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.35it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.93it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 347.10it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.21it/s]\n",
      "  1%|          | 4/500 [00:00<00:14, 33.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.00it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 215.99it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.48it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.62it/s]\n",
      "  2%|▏         | 8/500 [00:00<00:16, 29.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 42.82it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.91it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.57it/s]\n",
      "  2%|▏         | 11/500 [00:00<00:17, 27.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 230.20it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.19it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.68it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.30it/s]\n",
      "  3%|▎         | 15/500 [00:00<00:17, 28.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.68it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.43it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 52.68it/s]\n",
      "  4%|▎         | 18/500 [00:00<00:17, 27.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 250.81it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.48it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 209.61it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 279.88it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.55it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.91it/s]\n",
      "  5%|▍         | 24/500 [00:00<00:14, 32.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.42it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 204.09it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.28it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.05it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 208.33it/s]\n",
      "  6%|▌         | 29/500 [00:00<00:13, 35.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 276.92it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.55it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 334.10it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.77it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.22it/s]\n",
      "  7%|▋         | 34/500 [00:00<00:12, 38.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.55it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.75it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.40it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 191.16it/s]\n",
      "  8%|▊         | 38/500 [00:01<00:14, 30.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 207.80it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.38it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.60it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 194.60it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.41it/s]\n",
      "  9%|▊         | 43/500 [00:01<00:13, 33.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 197.08it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.48it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.70it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.44it/s]\n",
      "  9%|▉         | 47/500 [00:01<00:13, 34.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 176.49it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 168.86it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 72.40it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.44it/s]\n",
      " 10%|█         | 51/500 [00:01<00:12, 36.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.49it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 210.35it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.48it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 211.10it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 566.26it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 215.71it/s]\n",
      " 11%|█▏        | 57/500 [00:01<00:10, 41.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.57it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.48it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 42.14it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 158.23it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 179.99it/s]\n",
      " 12%|█▏        | 62/500 [00:01<00:11, 38.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.39it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 125.17it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 283.21it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.97it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 177.30it/s]\n",
      " 13%|█▎        | 67/500 [00:01<00:10, 39.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.58it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.97it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.53it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.94it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.68it/s]\n",
      " 14%|█▍        | 72/500 [00:02<00:10, 39.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.58it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.53it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.45it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.37it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.64it/s]\n",
      " 15%|█▌        | 77/500 [00:02<00:10, 39.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.07it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.24it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.11it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 256.22it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.56it/s]\n",
      " 16%|█▋        | 82/500 [00:02<00:11, 35.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.27it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.32it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.20it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.05it/s]\n",
      " 17%|█▋        | 86/500 [00:02<00:11, 35.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 225.88it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.68it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 244.49it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.82it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 192.89it/s]\n",
      " 18%|█▊        | 91/500 [00:02<00:10, 37.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.31it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.31it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.63it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 307.41it/s]\n",
      " 19%|█▉        | 95/500 [00:02<00:10, 37.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 165.87it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.18it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 140.61it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 172.09it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.31it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.58it/s]\n",
      " 20%|██        | 101/500 [00:02<00:09, 40.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.20it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.20it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.09it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.90it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.77it/s]\n",
      " 21%|██        | 106/500 [00:02<00:09, 39.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 344.73it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.26it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.22it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.99it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.66it/s]\n",
      " 22%|██▏       | 111/500 [00:03<00:11, 32.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 182.88it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.99it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 274.50it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.46it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.66it/s]\n",
      " 23%|██▎       | 116/500 [00:03<00:10, 35.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.65it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 64.26it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.72it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.92it/s]\n",
      " 24%|██▍       | 120/500 [00:03<00:13, 27.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.44it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 314.77it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.22it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.70it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.04it/s]\n",
      " 25%|██▌       | 125/500 [00:03<00:12, 31.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 182.85it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.88it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.82it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.84it/s]\n",
      " 26%|██▌       | 129/500 [00:03<00:11, 33.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 294.21it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 163.56it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.45it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.59it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.10it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.83it/s]\n",
      " 27%|██▋       | 135/500 [00:03<00:10, 35.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 186.65it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 156.28it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.64it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 198.26it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 376.95it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 141/500 [00:03<00:09, 39.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 204.16it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 257.00it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 196.38it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 149.50it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.96it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.98it/s]\n",
      " 29%|██▉       | 147/500 [00:04<00:08, 42.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.09it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 169.84it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.34it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 63.53it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.75it/s]\n",
      " 30%|███       | 152/500 [00:04<00:08, 42.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.57it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 175.32it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.96it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.83it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 155.37it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 287.87it/s]\n",
      " 32%|███▏      | 158/500 [00:04<00:07, 45.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 197.70it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.62it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 90.16it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.00it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.03it/s]\n",
      " 33%|███▎      | 163/500 [00:04<00:08, 41.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.28it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.42it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.98it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 304.97it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 31.37it/s]\n",
      " 34%|███▎      | 168/500 [00:04<00:09, 34.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.94it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 158.55it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 158.58it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.64it/s]\n",
      " 34%|███▍      | 172/500 [00:04<00:09, 35.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 159.32it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.98it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.13it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.95it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 738.04it/s]\n",
      " 35%|███▌      | 177/500 [00:04<00:08, 38.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 121.67it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.26it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.04it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.16it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.02it/s]\n",
      " 36%|███▋      | 182/500 [00:04<00:08, 38.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 282.96it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 221.09it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 196.00it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 248.43it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.11it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.99it/s]\n",
      " 38%|███▊      | 188/500 [00:05<00:07, 40.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.52it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.46it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.23it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.01it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.13it/s]\n",
      " 39%|███▊      | 193/500 [00:05<00:08, 36.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 40.44it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.00it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 163.56it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.49it/s]\n",
      " 39%|███▉      | 197/500 [00:05<00:09, 31.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 160.93it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.29it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.37it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 113.12it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 232.50it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 107.09it/s]\n",
      " 41%|████      | 203/500 [00:05<00:08, 35.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.55it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.19it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 340.28it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.85it/s]\n",
      " 41%|████▏     | 207/500 [00:05<00:08, 36.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.61it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.58it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.61it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.20it/s]\n",
      " 42%|████▏     | 211/500 [00:05<00:09, 30.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 147.45it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.87it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 200.96it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 395.43it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.14it/s]\n",
      " 43%|████▎     | 216/500 [00:05<00:08, 34.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.73it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.85it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.90it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 200.03it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.12it/s]\n",
      " 44%|████▍     | 221/500 [00:06<00:08, 34.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.36it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.40it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.95it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.39it/s]\n",
      " 45%|████▌     | 225/500 [00:06<00:08, 32.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.20it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 78.94it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.85it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 53.91it/s]\n",
      " 46%|████▌     | 229/500 [00:06<00:08, 33.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.92it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 191.06it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.89it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.32it/s]\n",
      " 47%|████▋     | 233/500 [00:06<00:08, 33.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.18it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.98it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 99.17it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.10it/s]\n",
      " 47%|████▋     | 237/500 [00:06<00:07, 33.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 129.36it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 93.39it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 218.44it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.83it/s]\n",
      " 48%|████▊     | 241/500 [00:06<00:07, 34.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 77.22it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.26it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.10it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.58it/s]\n",
      " 49%|████▉     | 245/500 [00:06<00:08, 30.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.75it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.96it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.02it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 109.54it/s]\n",
      " 50%|████▉     | 249/500 [00:06<00:07, 31.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 163.05it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.81it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.23it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 59.96it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 94.07it/s]\n",
      " 51%|█████     | 254/500 [00:07<00:07, 33.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 178.47it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 171.50it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 350.64it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 43.16it/s]\n",
      " 52%|█████▏    | 258/500 [00:07<00:06, 35.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 182.28it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.81it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 215.29it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.70it/s]\n",
      " 52%|█████▏    | 262/500 [00:07<00:17, 13.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.58it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.94it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 190.15it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 249.88it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.72it/s]\n",
      " 53%|█████▎    | 267/500 [00:07<00:13, 17.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 180.05it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 156.77it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.45it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.44it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.83it/s]\n",
      " 54%|█████▍    | 272/500 [00:08<00:10, 21.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 197.16it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 167.90it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 253.49it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.16it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.98it/s]\n",
      " 55%|█████▌    | 277/500 [00:08<00:09, 24.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.14it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.15it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 155.55it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 57.29it/s]\n",
      " 56%|█████▌    | 281/500 [00:08<00:08, 24.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 120.60it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.17it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 96.95it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 243.85it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.42it/s]\n",
      " 57%|█████▋    | 286/500 [00:08<00:07, 27.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 308.36it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.90it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 229.15it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.15it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 181.16it/s]\n",
      " 58%|█████▊    | 291/500 [00:08<00:06, 31.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 207.04it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.81it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 113.69it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.64it/s]\n",
      " 59%|█████▉    | 295/500 [00:08<00:06, 32.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.45it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 190.67it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.28it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 238.71it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.41it/s]\n",
      " 60%|██████    | 300/500 [00:08<00:05, 35.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.46it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 228.35it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 206.99it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 167.93it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 237.42it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.50it/s]\n",
      " 61%|██████    | 306/500 [00:08<00:04, 40.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 183.56it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.58it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 143.95it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.67it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 250.56it/s]\n",
      " 62%|██████▏   | 311/500 [00:09<00:04, 40.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 37.85it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.13it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.17it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.70it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.12it/s]\n",
      " 63%|██████▎   | 316/500 [00:09<00:05, 35.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.32it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 205.50it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 115.51it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 121.50it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 157.93it/s]\n",
      " 64%|██████▍   | 321/500 [00:09<00:04, 38.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 184.89it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 255.11it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 133.71it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.69it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 182.44it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.61it/s]\n",
      " 65%|██████▌   | 327/500 [00:09<00:04, 39.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.57it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.97it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.72it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.50it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.21it/s]\n",
      " 66%|██████▋   | 332/500 [00:09<00:04, 37.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.63it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 161.00it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 213.08it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.54it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 435.73it/s]\n",
      " 67%|██████▋   | 337/500 [00:09<00:04, 40.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.10it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.93it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 179.76it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 490.16it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.84it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.07it/s]\n",
      " 69%|██████▊   | 343/500 [00:09<00:03, 41.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 30.80it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.27it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 181.95it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.54it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.09it/s]\n",
      " 70%|██████▉   | 348/500 [00:10<00:04, 36.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 147.65it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.88it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.62it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 211.55it/s]\n",
      " 70%|███████   | 352/500 [00:10<00:03, 37.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.14it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.69it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.77it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 438.23it/s]\n",
      " 71%|███████   | 356/500 [00:10<00:03, 37.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.86it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.39it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 165.10it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.61it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.81it/s]\n",
      " 72%|███████▏  | 361/500 [00:10<00:03, 37.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 171.50it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 157.06it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 22.65it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 101.67it/s]\n",
      " 73%|███████▎  | 365/500 [00:10<00:04, 31.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.38it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.00it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 145.61it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 334.10it/s]\n",
      " 74%|███████▍  | 369/500 [00:10<00:03, 32.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 165.97it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.56it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.67it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.54it/s]\n",
      " 75%|███████▍  | 373/500 [00:10<00:04, 31.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.03it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.43it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 151.61it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.41it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.37it/s]\n",
      " 76%|███████▌  | 378/500 [00:10<00:03, 33.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 178.00it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 98.46it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.14it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.15it/s]\n",
      " 76%|███████▋  | 382/500 [00:11<00:04, 29.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 162.05it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 201.25it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 73.84it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.63it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 214.37it/s]\n",
      " 77%|███████▋  | 387/500 [00:11<00:03, 33.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 285.06it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 311.31it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 175.53it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 122.09it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.91it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 168.41it/s]\n",
      " 79%|███████▊  | 393/500 [00:11<00:02, 37.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 82.78it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 490.16it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 46.68it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.54it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.09it/s]\n",
      " 80%|███████▉  | 398/500 [00:11<00:02, 36.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.48it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 174.25it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 180.83it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.04it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 81.11it/s]\n",
      " 81%|████████  | 403/500 [00:11<00:02, 38.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 123.57it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 256.39it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.19it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 151.56it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 95.98it/s]\n",
      " 82%|████████▏ | 408/500 [00:11<00:02, 40.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 164.37it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.25it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 125.31it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.87it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 377.70it/s]\n",
      " 83%|████████▎ | 413/500 [00:11<00:02, 36.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 126.28it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.06it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.31it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 185.57it/s]\n",
      " 83%|████████▎ | 417/500 [00:12<00:02, 35.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 55.04it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.40it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 108.87it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.93it/s]\n",
      " 84%|████████▍ | 421/500 [00:12<00:02, 33.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 207.65it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 128.09it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 64.21it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.85it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 219.25it/s]\n",
      " 85%|████████▌ | 426/500 [00:12<00:02, 36.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 147.43it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.11it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.49it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.36it/s]\n",
      " 86%|████████▌ | 430/500 [00:12<00:01, 35.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 97.33it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 153.41it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 48.42it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 146.09it/s]\n",
      " 87%|████████▋ | 434/500 [00:12<00:01, 34.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.76it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.59it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 157.48it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.39it/s]\n",
      " 88%|████████▊ | 438/500 [00:12<00:01, 33.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.59it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 120.49it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.76it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 390.35it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 328.84it/s]\n",
      " 89%|████████▊ | 443/500 [00:12<00:01, 36.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.65it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 187.69it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.12it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.11it/s]\n",
      " 89%|████████▉ | 447/500 [00:12<00:01, 35.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 39.07it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.79it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 103.24it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.59it/s]\n",
      " 90%|█████████ | 451/500 [00:12<00:01, 33.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 163.48it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 199.60it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 254.45it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 233.52it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 84.96it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.51it/s]\n",
      " 91%|█████████▏| 457/500 [00:13<00:01, 37.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 131.60it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 106.62it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 137.18it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 117.92it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 79.27it/s]\n",
      " 92%|█████████▏| 462/500 [00:13<00:00, 38.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 113.93it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 36.25it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.95it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.72it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 105.33it/s]\n",
      " 93%|█████████▎| 467/500 [00:13<00:00, 34.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 127.96it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 118.48it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 205.94it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 144.07it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 185.67it/s]\n",
      " 94%|█████████▍| 472/500 [00:13<00:00, 37.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.36it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 75.62it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 113.15it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 47.23it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 176.21it/s]\n",
      " 95%|█████████▌| 477/500 [00:13<00:00, 36.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 154.20it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 45.11it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 307.12it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.50it/s]\n",
      " 96%|█████████▌| 481/500 [00:13<00:00, 35.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 192.75it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 212.94it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 256.08it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.96it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 141.94it/s]\n",
      " 97%|█████████▋| 486/500 [00:13<00:00, 38.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 88.14it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 85.38it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 92.77it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 207.85it/s]\n",
      " 98%|█████████▊| 490/500 [00:13<00:00, 38.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 786.04it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.51it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 56.67it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 193.12it/s]\n",
      " 99%|█████████▉| 494/500 [00:14<00:00, 38.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 170.94it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 207.99it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 150.74it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 179.64it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.94it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 70.46it/s]\n",
      "100%|██████████| 500/500 [00:14<00:00, 35.18it/s]\n"
     ]
    }
   ],
   "source": [
    "experimental_data_text_purturbed = []\n",
    "experimental_data_y_text_purturbed = []\n",
    "\n",
    "for case_no_ in tqdm(random_cases):\n",
    "    pt, c = text_purt_clas(case_no_)\n",
    "    experimental_data_text_purturbed.append(pt)\n",
    "    experimental_data_y_text_purturbed.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Experimental Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_data = pd.DataFrame()\n",
    "experimental_data['idx'] = experimental_data_idx\n",
    "experimental_data['text'] = experimental_data_text\n",
    "experimental_data['y'] = experimental_data_y\n",
    "experimental_data['y_hat'] = experimental_data_y_hat\n",
    "experimental_data['text_purturbed'] = experimental_data_text_purturbed\n",
    "experimental_data['y_text_purturbed'] = experimental_data_y_text_purturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "      <th>y_hat</th>\n",
       "      <th>text_purturbed</th>\n",
       "      <th>y_text_purturbed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As a Dane I'm proud of the handful of good Dan...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>**especi** a Dane I 'm proud of **whi** handfu...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I watched this movie purely for the setting. I...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>**quit** watched **top** movie purely for **re...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The blend of biography with poetry and live ac...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>The blend of biography with poetry and live ac...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A severe backwards step for the puppets in thi...</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "      <td>A severe backwards step for the puppets in thi...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Based on the 1952 autobiography \"A Many-Splend...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>Based on the 1952 autobiography `` A Many-Sple...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                               text    y y_hat  \\\n",
       "0    0  As a Dane I'm proud of the handful of good Dan...  neg   neg   \n",
       "1    1  I watched this movie purely for the setting. I...  neg   neg   \n",
       "2    2  The blend of biography with poetry and live ac...  pos   pos   \n",
       "3    3  A severe backwards step for the puppets in thi...  neg   pos   \n",
       "4    4  Based on the 1952 autobiography \"A Many-Splend...  pos   pos   \n",
       "\n",
       "                                      text_purturbed y_text_purturbed  \n",
       "0  **especi** a Dane I 'm proud of **whi** handfu...              neg  \n",
       "1  **quit** watched **top** movie purely for **re...              neg  \n",
       "2  The blend of biography with poetry and live ac...              pos  \n",
       "3  A severe backwards step for the puppets in thi...              pos  \n",
       "4  Based on the 1952 autobiography `` A Many-Sple...              pos  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_data.to_csv('experimental_data_anndt_210303.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
